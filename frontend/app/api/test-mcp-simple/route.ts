import { NextRequest } from 'next/server';
import { streamText } from 'ai';
import { createOpenAI } from '@ai-sdk/openai';

// åˆ›å»ºAIå®¢æˆ·ç«¯
function createAIClient() {
  try {
    const provider = process.env.AI_PROVIDER || 'openrouter';
    const openRouterKey = process.env.OPENROUTER_API_KEY;
    const openAIKey = process.env.OPENAI_API_KEY;
    
    console.log('AIå®¢æˆ·ç«¯é…ç½®æ£€æŸ¥:', {
      provider,
      openRouterKey: openRouterKey ? `set (${openRouterKey.length} chars)` : 'not set',
      openAIKey: openAIKey ? `set (${openAIKey.length} chars)` : 'not set'
    });
    
    if (provider === 'openrouter' && openRouterKey && openRouterKey.length > 10) {
      const client = createOpenAI({
        baseURL: 'https://openrouter.ai/api/v1',
        apiKey: openRouterKey,
      });
      const model = process.env.OPENROUTER_MODEL || 'anthropic/claude-3-haiku';
      console.log(`âœ… ä½¿ç”¨OpenRouter AIæ¨¡å‹: ${model}`);
      return client(model);
    }
    
    if (provider === 'openai' && openAIKey && openAIKey.startsWith('sk-')) {
      const client = createOpenAI({
        baseURL: 'https://api.openai.com/v1',
        apiKey: openAIKey,
      });
      const model = process.env.OPENAI_MODEL || 'gpt-4o-mini';
      console.log(`âœ… ä½¿ç”¨OpenAIæ¨¡å‹: ${model}`);
      return client(model);
    }

    console.log('âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„AI APIå¯†é’¥');
    return null;

  } catch (error) {
    console.error('âŒ åˆ›å»ºAIå®¢æˆ·ç«¯å¤±è´¥:', error);
    return null;
  }
}

export async function POST(req: NextRequest) {
  try {
    console.log('ğŸ“ å¼€å§‹å¤„ç†ç®€åŒ–MCPæµ‹è¯•è¯·æ±‚');
    
    const { messages } = await req.json();
    console.log('ğŸ“ æ¥æ”¶åˆ°æ¶ˆæ¯:', messages);

    // åˆ›å»ºAIæ¨¡å‹å®ä¾‹
    console.log('ğŸ¤– åˆ›å»ºAIå®¢æˆ·ç«¯...');
    const aiModel = createAIClient();
    if (!aiModel) {
      console.error('âŒ AIå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥');
      return new Response(
        JSON.stringify({ error: 'AIé…ç½®æ— æ•ˆï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡' }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      );
    }

    console.log('ğŸ”„ å¼€å§‹è°ƒç”¨streamText (æ— å·¥å…·)...');
    
    try {
      // ç®€å•çš„streamTextè°ƒç”¨ï¼Œä¸ä½¿ç”¨å·¥å…·
      const result = await streamText({
        model: aiModel,
        messages,
        system: 'ä½ æ˜¯ä¸€ä¸ªç½‘ç»œè¯Šæ–­åŠ©æ‰‹ã€‚è¯·ç®€å•å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚',
        maxTokens: 200,
        temperature: 0.7
      });

      console.log('âœ… streamTextè°ƒç”¨æˆåŠŸ');
      return result.toDataStreamResponse();
    } catch (streamError) {
      console.error('âŒ streamTextè°ƒç”¨å¤±è´¥:', streamError);
      return new Response(
        JSON.stringify({ 
          error: 'AIæµå¼å¤„ç†å¤±è´¥', 
          details: (streamError as Error).message,
          stack: (streamError as Error).stack 
        }),
        { status: 500, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
  } catch (error) {
    console.error('âŒ ç®€åŒ–MCPæµ‹è¯•APIé”™è¯¯:', error);
    console.error('é”™è¯¯è¯¦æƒ…:', {
      message: (error as Error)?.message,
      stack: (error as Error)?.stack
    });
    
    return new Response(
      JSON.stringify({ 
        error: 'å†…éƒ¨æœåŠ¡å™¨é”™è¯¯',
        details: (error as Error)?.message || 'Unknown error',
        stack: (error as Error)?.stack 
      }),
      { 
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    );
  }
} 