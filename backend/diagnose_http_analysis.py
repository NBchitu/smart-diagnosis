#!/usr/bin/env python3
"""
è¯Šæ–­HTTPåˆ†æé—®é¢˜
æ£€æŸ¥ä¸ºä»€ä¹ˆæ²¡æœ‰æ˜¾ç¤ºå…·ä½“çš„ç½‘ç«™è®¿é—®è®°å½•
"""

import requests
import time
import json
import threading
import subprocess
import os

def generate_clear_http_traffic():
    """ç”Ÿæˆæ˜ç¡®çš„HTTPæµé‡"""
    print("ğŸŒ ç”Ÿæˆæ˜ç¡®çš„HTTPæµé‡...")
    
    # ä½¿ç”¨æ˜ç¡®ä¼šäº§ç”ŸHTTPæµé‡çš„URL
    test_urls = [
        'http://httpbin.org/get',
        'http://httpbin.org/delay/1',
        'http://httpbin.org/status/200',
        'http://httpbin.org/status/404',
        'http://example.com',
        'http://httpbin.org/json',
    ]
    
    def make_requests():
        for i, url in enumerate(test_urls):
            try:
                print(f"   {i+1}. è®¿é—®: {url}")
                response = requests.get(url, timeout=10)
                print(f"      å“åº”: {response.status_code} ({len(response.content)} bytes)")
                time.sleep(1.5)  # é—´éš”æ—¶é—´ï¼Œä¾¿äºæŠ“åŒ…
            except Exception as e:
                print(f"      å¼‚å¸¸: {str(e)}")
    
    thread = threading.Thread(target=make_requests)
    thread.daemon = True
    thread.start()
    
    return thread

def test_http_analysis_step_by_step():
    """é€æ­¥æµ‹è¯•HTTPåˆ†æ"""
    print("ğŸ” é€æ­¥è¯Šæ–­HTTPåˆ†æé—®é¢˜")
    print("=" * 60)
    
    # ç”ŸæˆHTTPæµé‡
    traffic_thread = generate_clear_http_traffic()
    
    # åˆ›å»ºHTTPåˆ†æè¯·æ±‚
    test_request = {
        "issue_type": "http",
        "duration": 12,  # æ›´é•¿çš„æŠ“åŒ…æ—¶é—´
        "user_description": "HTTPåˆ†æè¯Šæ–­æµ‹è¯• - æ£€æŸ¥ç½‘ç«™è®¿é—®è®°å½•",
        "enable_ai_analysis": True
    }
    
    try:
        print("\n1ï¸âƒ£ å‘é€HTTPåˆ†æè¯·æ±‚...")
        response = requests.post(
            'http://localhost:8000/api/capture',
            json=test_request,
            timeout=10
        )
        
        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"å“åº”: {response.text}")
            return False
        
        data = response.json()
        task_id = data.get('task_id')
        print(f"   âœ… ä»»åŠ¡åˆ›å»º: {task_id}")
        
        # ç­‰å¾…æµé‡ç”Ÿæˆå®Œæˆ
        print("\n2ï¸âƒ£ ç­‰å¾…HTTPæµé‡ç”Ÿæˆ...")
        traffic_thread.join(timeout=15)
        print("   âœ… HTTPæµé‡ç”Ÿæˆå®Œæˆ")
        
        print("\n3ï¸âƒ£ ç›‘æ§ä»»åŠ¡è¿›åº¦...")
        
        # ç›‘æ§ä»»åŠ¡è¿›åº¦
        for i in range(45):
            time.sleep(2)
            
            try:
                status_response = requests.get(f'http://localhost:8000/api/capture/status?task_id={task_id}')
                if status_response.status_code == 200:
                    status_data = status_response.json()
                    status = status_data.get('status')
                    progress = status_data.get('progress', 0)
                    
                    print(f"   ğŸ“Š {i*2}s: {status} ({progress}%)")
                    
                    if status == 'done':
                        print("   âœ… ä»»åŠ¡å®Œæˆ")
                        break
                    elif status == 'error':
                        error = status_data.get('error', '')
                        print(f"   âŒ ä»»åŠ¡å¤±è´¥: {error}")
                        return False
                else:
                    print(f"   âŒ çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {status_response.status_code}")
                    break
            except Exception as e:
                print(f"   âŒ çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
                break
        
        print("\n4ï¸âƒ£ è¯¦ç»†åˆ†æç»“æœ...")
        
        # è·å–è¯¦ç»†ç»“æœ
        result_response = requests.get(f'http://localhost:8000/api/capture/result?task_id={task_id}')
        if result_response.status_code != 200:
            print(f"âŒ è·å–ç»“æœå¤±è´¥: {result_response.status_code}")
            return False
        
        result_data = result_response.json()
        result = result_data.get('result', {})
        
        # åˆ†ææŠ“åŒ…æ‘˜è¦
        capture_summary = result.get('capture_summary', {})
        print(f"   ğŸ“Š æŠ“åŒ…æ‘˜è¦:")
        print(f"     æ–‡ä»¶å¤§å°: {capture_summary.get('file_size', 0):,} bytes")
        print(f"     è§£ææ–¹æ³•: {capture_summary.get('parsing_method', 'unknown')}")
        
        # åˆ†æå¢å¼ºåˆ†ææ•°æ®
        enhanced_analysis = capture_summary.get('enhanced_analysis', {})
        if enhanced_analysis:
            print(f"   âœ… åŒ…å«å¢å¼ºåˆ†ææ•°æ®")
            
            # æ£€æŸ¥åŸºç¡€ç»Ÿè®¡
            basic_stats = enhanced_analysis.get('basic_stats', {})
            if basic_stats:
                total_packets = basic_stats.get('total_packets', 0)
                protocols = basic_stats.get('protocols', {})
                print(f"     åŸºç¡€ç»Ÿè®¡: {total_packets} ä¸ªåŒ…")
                print(f"     åè®®åˆ†å¸ƒ: {protocols}")
            
            # æ£€æŸ¥HTTPåˆ†æ
            http_analysis = enhanced_analysis.get('http_analysis', {})
            if http_analysis:
                print(f"   âœ… åŒ…å«HTTPåˆ†ææ•°æ®")
                
                basic_summary = http_analysis.get('basic_summary', {})
                https_connections = http_analysis.get('https_connections', {})
                
                print(f"     HTTPåŸºç¡€æ‘˜è¦: {basic_summary}")
                print(f"     HTTPSè¿æ¥: {https_connections}")
            else:
                print(f"   âŒ ç¼ºå°‘HTTPåˆ†ææ•°æ®")
            
            # æ£€æŸ¥é—®é¢˜ç‰¹å®šæ´å¯Ÿ
            issue_insights = enhanced_analysis.get('issue_specific_insights', {})
            if issue_insights:
                print(f"   âœ… åŒ…å«é—®é¢˜ç‰¹å®šæ´å¯Ÿ")
                
                website_performance = issue_insights.get('website_performance', {})
                if website_performance:
                    print(f"   ğŸ¯ ç½‘ç«™æ€§èƒ½æ•°æ®:")
                    print(f"     åˆ†æäº† {len(website_performance)} ä¸ªç½‘ç«™")
                    
                    for host, perf_data in website_performance.items():
                        ips = perf_data.get('ips', [])
                        http_time = perf_data.get('http_response_time', {})
                        tcp_time = perf_data.get('tcp_rtt', {})
                        requests_data = perf_data.get('requests', {})
                        
                        print(f"     ğŸ“Š {host}:")
                        print(f"       IP: {ips}")
                        print(f"       HTTPæ—¶é—´: {http_time}")
                        print(f"       TCPæ—¶é—´: {tcp_time}")
                        print(f"       è¯·æ±‚ç»Ÿè®¡: {requests_data}")
                else:
                    print(f"   âŒ ç¼ºå°‘ç½‘ç«™æ€§èƒ½æ•°æ®")
                    
                performance_issues = issue_insights.get('performance_issues', [])
                if performance_issues:
                    print(f"   âš ï¸ æ€§èƒ½é—®é¢˜:")
                    for issue in performance_issues:
                        print(f"     - {issue}")
            else:
                print(f"   âŒ ç¼ºå°‘é—®é¢˜ç‰¹å®šæ´å¯Ÿ")
            
            # æ£€æŸ¥è¯Šæ–­çº¿ç´¢
            diagnostic_clues = enhanced_analysis.get('diagnostic_clues', [])
            if diagnostic_clues:
                print(f"\n   ğŸ’¡ è¯Šæ–­çº¿ç´¢ ({len(diagnostic_clues)} æ¡):")
                for i, clue in enumerate(diagnostic_clues, 1):
                    print(f"     {i}. {clue}")
                    
                # æ£€æŸ¥æ˜¯å¦æœ‰ç½‘ç«™ç‰¹å®šçº¿ç´¢
                website_clues = [clue for clue in diagnostic_clues if 'ğŸ“Š' in clue and 'IP:' in clue]
                if website_clues:
                    print(f"   âœ… æ‰¾åˆ° {len(website_clues)} æ¡ç½‘ç«™ç‰¹å®šçº¿ç´¢")
                else:
                    print(f"   âŒ æ²¡æœ‰æ‰¾åˆ°ç½‘ç«™ç‰¹å®šçº¿ç´¢")
            else:
                print(f"   âŒ ç¼ºå°‘è¯Šæ–­çº¿ç´¢")
        else:
            print(f"   âŒ ç¼ºå°‘å¢å¼ºåˆ†ææ•°æ®")
        
        # æ£€æŸ¥AIåˆ†æç»“æœ
        ai_analysis = result.get('ai_analysis', {})
        if ai_analysis:
            if ai_analysis.get('success'):
                print(f"\n   ğŸ¤– AIåˆ†ææˆåŠŸ")
                analysis_content = ai_analysis.get('analysis', {})
                diagnosis = analysis_content.get('diagnosis', '')
                print(f"     è¯Šæ–­: {diagnosis}")
            else:
                error = ai_analysis.get('error', '')
                print(f"\n   âŒ AIåˆ†æå¤±è´¥: {error}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯Šæ–­å¼‚å¸¸: {str(e)}")
        return False

def check_tshark_http_capability():
    """æ£€æŸ¥tsharkçš„HTTPè§£æèƒ½åŠ›"""
    print("\nğŸ”§ æ£€æŸ¥tshark HTTPè§£æèƒ½åŠ›...")
    
    try:
        # æ£€æŸ¥tsharkæ˜¯å¦å¯ç”¨
        tshark_paths = [
            '/opt/homebrew/bin/tshark',
            '/usr/local/bin/tshark',
            '/usr/bin/tshark',
            'tshark'
        ]
        
        tshark_cmd = None
        for path in tshark_paths:
            try:
                result = subprocess.run([path, '-v'], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    tshark_cmd = path
                    print(f"   âœ… æ‰¾åˆ°tshark: {path}")
                    break
            except:
                continue
        
        if not tshark_cmd:
            print("   âŒ tsharkä¸å¯ç”¨")
            return False
        
        # æ£€æŸ¥HTTPå­—æ®µæ”¯æŒ
        http_fields = [
            'http.host',
            'http.time',
            'http.response.code',
            'tcp.analysis.ack_rtt'
        ]
        
        print("   ğŸ” æ£€æŸ¥HTTPå­—æ®µæ”¯æŒ:")
        for field in http_fields:
            try:
                result = subprocess.run([
                    tshark_cmd, '-G', 'fields'
                ], capture_output=True, text=True, timeout=10)
                
                if field in result.stdout:
                    print(f"     âœ… {field}")
                else:
                    print(f"     âŒ {field}")
            except Exception as e:
                print(f"     âŒ {field} (æ£€æŸ¥å¤±è´¥: {str(e)})")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ£€æŸ¥å¼‚å¸¸: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ HTTPåˆ†æé—®é¢˜è¯Šæ–­")
    print("=" * 70)
    
    # æ£€æŸ¥tsharkèƒ½åŠ›
    tshark_ok = check_tshark_http_capability()
    
    # æµ‹è¯•HTTPåˆ†æ
    analysis_ok = test_http_analysis_step_by_step()
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ è¯Šæ–­æ€»ç»“:")
    print("=" * 70)
    
    if tshark_ok and analysis_ok:
        print("ğŸ‰ HTTPåˆ†æåŠŸèƒ½æ­£å¸¸ï¼")
        print("\nâœ… è¯Šæ–­ç»“æœ:")
        print("   - tshark HTTPè§£æèƒ½åŠ›æ­£å¸¸")
        print("   - ç½‘ç«™æ€§èƒ½æ•°æ®ç”Ÿæˆæ­£å¸¸")
        print("   - è¯Šæ–­çº¿ç´¢æ˜¾ç¤ºæ­£å¸¸")
        
    else:
        print("âŒ HTTPåˆ†æå­˜åœ¨é—®é¢˜")
        print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
        if not tshark_ok:
            print("   - tsharkå·¥å…·ä¸å¯ç”¨æˆ–ä¸æ”¯æŒHTTPè§£æ")
        if not analysis_ok:
            print("   - HTTPæµé‡æ•è·å¤±è´¥")
            print("   - ç½‘ç«™æ€§èƒ½æ•°æ®ç”Ÿæˆå¤±è´¥")
            print("   - åˆ†æé€»è¾‘æœ‰bug")
        
        print("\nğŸ”§ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
        print("   1. ç¡®ä¿åœ¨æŠ“åŒ…æœŸé—´æœ‰å®é™…çš„HTTPæµé‡")
        print("   2. æ£€æŸ¥tsharkæ˜¯å¦æ­£ç¡®å®‰è£…")
        print("   3. éªŒè¯HTTPåˆ†æé€»è¾‘")
        print("   4. æ£€æŸ¥æƒé™é—®é¢˜")
    
    return tshark_ok and analysis_ok

if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)
