#!/usr/bin/env python3
"""
æµ‹è¯•èšç„¦çš„HTTPåˆ†æåŠŸèƒ½
éªŒè¯åŸŸå-IP-å“åº”æ—¶å»¶å…³è”åˆ†æ
"""

import requests
import time
import json
import threading

def generate_focused_http_traffic():
    """ç”Ÿæˆèšç„¦çš„HTTPæµ‹è¯•æµé‡"""
    print("ğŸŒ ç”Ÿæˆèšç„¦çš„HTTPæµ‹è¯•æµé‡...")
    
    # è®¿é—®ä¸åŒçš„ç½‘ç«™æ¥ç”Ÿæˆæœ‰æ„ä¹‰çš„æµé‡
    test_sites = [
        'http://httpbin.org/delay/1',    # 1ç§’å»¶è¿Ÿ
        'http://httpbin.org/delay/2',    # 2ç§’å»¶è¿Ÿ  
        'http://httpbin.org/status/200', # æ­£å¸¸å“åº”
        'http://httpbin.org/status/404', # 404é”™è¯¯
        'http://httpbin.org/status/500', # 500é”™è¯¯
        'http://httpbin.org/get',        # æ­£å¸¸GET
    ]
    
    def make_test_requests():
        for url in test_sites:
            try:
                print(f"   è®¿é—®: {url}")
                requests.get(url, timeout=10)
                time.sleep(0.5)
            except Exception as e:
                print(f"   è¯·æ±‚å¤±è´¥: {url} - {str(e)}")
    
    # åœ¨åå°çº¿ç¨‹ä¸­ç”Ÿæˆæµé‡
    thread = threading.Thread(target=make_test_requests)
    thread.daemon = True
    thread.start()
    
    return thread

def test_focused_http_analysis():
    """æµ‹è¯•èšç„¦çš„HTTPåˆ†æåŠŸèƒ½"""
    print("ğŸ¯ æµ‹è¯•èšç„¦çš„HTTPåˆ†æåŠŸèƒ½")
    print("=" * 60)
    
    # ç”Ÿæˆæµ‹è¯•æµé‡
    traffic_thread = generate_focused_http_traffic()
    
    # åˆ›å»ºHTTPé—®é¢˜ç±»å‹çš„æµ‹è¯•è¯·æ±‚
    test_request = {
        "issue_type": "http",
        "duration": 8,  # è¶³å¤Ÿçš„æ—¶é—´æ•è·HTTPæµé‡
        "user_description": "èšç„¦HTTPåˆ†ææµ‹è¯• - åŸŸåIPæ—¶å»¶å…³è”",
        "enable_ai_analysis": True
    }
    
    try:
        print("\n1ï¸âƒ£ å‘é€èšç„¦HTTPåˆ†æè¯·æ±‚...")
        response = requests.post(
            'http://localhost:8000/api/capture',
            json=test_request,
            timeout=10
        )
        
        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return False
        
        data = response.json()
        task_id = data.get('task_id')
        print(f"   âœ… ä»»åŠ¡åˆ›å»º: {task_id}")
        
        # ç­‰å¾…æµé‡ç”Ÿæˆå®Œæˆ
        traffic_thread.join(timeout=10)
        
        print("\n2ï¸âƒ£ ç­‰å¾…åˆ†æå®Œæˆ...")
        
        # ç›‘æ§ä»»åŠ¡è¿›åº¦
        for i in range(35):
            time.sleep(2)
            
            status_response = requests.get(f'http://localhost:8000/api/capture/status?task_id={task_id}')
            if status_response.status_code == 200:
                status_data = status_response.json()
                status = status_data.get('status')
                progress = status_data.get('progress', 0)
                
                print(f"   ğŸ“Š {i*2}s: {status} ({progress}%)")
                
                if status == 'done':
                    print("   âœ… ä»»åŠ¡å®Œæˆ")
                    break
                elif status == 'error':
                    print(f"   âŒ ä»»åŠ¡å¤±è´¥: {status_data.get('error')}")
                    return False
        
        print("\n3ï¸âƒ£ åˆ†æèšç„¦çš„HTTPæ•°æ®...")
        
        # è·å–ç»“æœ
        result_response = requests.get(f'http://localhost:8000/api/capture/result?task_id={task_id}')
        if result_response.status_code != 200:
            print(f"âŒ è·å–ç»“æœå¤±è´¥: {result_response.status_code}")
            return False
        
        result_data = result_response.json()
        result = result_data.get('result', {})
        
        # æ£€æŸ¥AIåˆ†æç»“æœ
        ai_analysis = result.get('ai_analysis', {})
        if ai_analysis and ai_analysis.get('success'):
            print("   âœ… AIåˆ†ææˆåŠŸå®Œæˆ")
            analysis_content = ai_analysis.get('analysis', {})
            diagnosis = analysis_content.get('diagnosis', '')
            if diagnosis:
                print(f"   ğŸ¤– AIè¯Šæ–­: {diagnosis[:200]}...")
        
        # åˆ†æèšç„¦çš„HTTPæ•°æ®
        capture_summary = result.get('capture_summary', {})
        enhanced_analysis = capture_summary.get('enhanced_analysis', {})
        
        if not enhanced_analysis:
            print("   âŒ æ²¡æœ‰å¢å¼ºåˆ†ææ•°æ®")
            return False
        
        # æ£€æŸ¥é—®é¢˜ç‰¹å®šæ´å¯Ÿ
        issue_insights = enhanced_analysis.get('issue_specific_insights', {})
        if issue_insights:
            print("   âœ… åŒ…å«HTTPé—®é¢˜ç‰¹å®šåˆ†æ")
            
            # ç½‘ç«™æ€§èƒ½æ•°æ® - æ ¸å¿ƒå…³æ³¨ç‚¹
            website_performance = issue_insights.get('website_performance', {})
            if website_performance:
                print(f"\n   ğŸ¯ ç½‘ç«™æ€§èƒ½åˆ†æ (åŸŸå-IP-æ—¶å»¶å…³è”):")
                print(f"   åˆ†æäº† {len(website_performance)} ä¸ªç½‘ç«™")
                
                for host, perf_data in website_performance.items():
                    print(f"\n   ğŸ“Š {host}:")
                    
                    # IPåœ°å€
                    ips = perf_data.get('ips', [])
                    if ips:
                        print(f"     IPåœ°å€: {', '.join(ips)}")
                    
                    # HTTPå“åº”æ—¶é—´
                    http_time = perf_data.get('http_response_time', {})
                    if http_time:
                        avg_ms = http_time.get('avg_ms', 0)
                        max_ms = http_time.get('max_ms', 0)
                        samples = http_time.get('samples', 0)
                        print(f"     HTTPå“åº”æ—¶é—´: å¹³å‡{avg_ms}ms, æœ€å¤§{max_ms}ms ({samples}ä¸ªæ ·æœ¬)")
                    
                    # TCP RTT
                    tcp_time = perf_data.get('tcp_rtt', {})
                    if tcp_time:
                        avg_ms = tcp_time.get('avg_ms', 0)
                        max_ms = tcp_time.get('max_ms', 0)
                        samples = tcp_time.get('samples', 0)
                        print(f"     TCP RTT: å¹³å‡{avg_ms}ms, æœ€å¤§{max_ms}ms ({samples}ä¸ªæ ·æœ¬)")
                    
                    # è¯·æ±‚ç»Ÿè®¡
                    requests_data = perf_data.get('requests', {})
                    if requests_data:
                        total = requests_data.get('total', 0)
                        errors = requests_data.get('errors', 0)
                        error_rate = requests_data.get('error_rate_percent', 0)
                        print(f"     è¯·æ±‚ç»Ÿè®¡: {total}ä¸ªè¯·æ±‚, {errors}ä¸ªé”™è¯¯ ({error_rate}%)")
                        
                        error_codes = requests_data.get('error_codes', {})
                        if error_codes:
                            print(f"     é”™è¯¯è¯¦æƒ…: {error_codes}")
                    
                    # è®¿é—®æ—¶é•¿
                    duration = perf_data.get('access_duration_seconds')
                    if duration is not None:
                        print(f"     è®¿é—®æ—¶é•¿: {duration}ç§’")
            
            # æ€§èƒ½é—®é¢˜åˆ—è¡¨
            performance_issues = issue_insights.get('performance_issues', [])
            if performance_issues:
                print(f"\n   âš ï¸ æ£€æµ‹åˆ°çš„æ€§èƒ½é—®é¢˜:")
                for i, issue in enumerate(performance_issues, 1):
                    print(f"     {i}. {issue}")
            else:
                print(f"\n   âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„æ€§èƒ½é—®é¢˜")
            
            # å“åº”æ‘˜è¦
            response_summary = issue_insights.get('response_summary', {})
            if response_summary:
                websites = response_summary.get('websites_accessed', 0)
                total_req = response_summary.get('total_requests', 0)
                total_err = response_summary.get('total_errors', 0)
                error_rate = response_summary.get('overall_error_rate_percent', 0)
                
                print(f"\n   ğŸ“ˆ æ€»ä½“æ‘˜è¦:")
                print(f"     è®¿é—®ç½‘ç«™: {websites}ä¸ª")
                print(f"     æ€»è¯·æ±‚æ•°: {total_req}ä¸ª")
                print(f"     æ€»é”™è¯¯æ•°: {total_err}ä¸ª")
                print(f"     æ•´ä½“é”™è¯¯ç‡: {error_rate}%")
        
        # è¯Šæ–­çº¿ç´¢
        diagnostic_clues = enhanced_analysis.get('diagnostic_clues', [])
        if diagnostic_clues:
            print(f"\n   ğŸ’¡ èšç„¦çš„è¯Šæ–­çº¿ç´¢:")
            for i, clue in enumerate(diagnostic_clues, 1):
                if 'ğŸŒ' in clue or 'ğŸ“Š' in clue or 'ğŸŒ' in clue or 'ğŸ“¡' in clue or 'âŒ' in clue:
                    print(f"     {i}. {clue}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {str(e)}")
        return False

def compare_analysis_focus():
    """å¯¹æ¯”åˆ†æèšç„¦åº¦"""
    print("\nğŸ” åˆ†æèšç„¦åº¦å¯¹æ¯”")
    print("=" * 60)
    
    print("ğŸ“Š é‡æ„å‰çš„HTTPåˆ†æ:")
    print("   - HTTPæ–¹æ³•ç»Ÿè®¡ (GET, POST, PUT...)")
    print("   - è¯·æ±‚URIè·¯å¾„åˆ—è¡¨")
    print("   - User-Agentç»Ÿè®¡")
    print("   - å†…å®¹ç±»å‹åˆ†å¸ƒ")
    print("   - Cookieå’ŒRefererä¿¡æ¯")
    print("   - å¤§æ–‡ä»¶ä¸‹è½½æ£€æµ‹")
    print("   âŒ ä¿¡æ¯åˆ†æ•£ï¼Œç¼ºä¹å…³è”æ€§")
    
    print("\nğŸ¯ é‡æ„åçš„èšç„¦åˆ†æ:")
    print("   - åŸŸå â†” IPåœ°å€æ˜ å°„")
    print("   - åŸŸå â†” HTTPå“åº”æ—¶é—´å…³è”")
    print("   - åŸŸå â†” TCP RTTå…³è”")
    print("   - åŸŸå â†” é”™è¯¯ç‡å…³è”")
    print("   - æ€§èƒ½é—®é¢˜ç›´æ¥å®šä½åˆ°å…·ä½“ç½‘ç«™")
    print("   âœ… ä¿¡æ¯èšç„¦ï¼Œç›´æ¥å¯æ“ä½œ")
    
    print("\nğŸ’¡ èšç„¦åˆ†æçš„ä»·å€¼:")
    print("   - ç›´æ¥å›ç­”: 'å“ªä¸ªç½‘ç«™æ…¢ï¼Ÿ'")
    print("   - ç›´æ¥å›ç­”: 'æ…¢åœ¨å“ªé‡Œï¼Ÿ(DNS/TCP/HTTP)'")
    print("   - ç›´æ¥å›ç­”: 'IPåœ°å€æ˜¯å¦æœ‰é—®é¢˜ï¼Ÿ'")
    print("   - ç›´æ¥å›ç­”: 'é”™è¯¯é›†ä¸­åœ¨å“ªä¸ªç½‘ç«™ï¼Ÿ'")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ èšç„¦HTTPåˆ†æåŠŸèƒ½æµ‹è¯•")
    print("=" * 70)
    
    # æµ‹è¯•èšç„¦åˆ†æ
    focused_ok = test_focused_http_analysis()
    
    # å¯¹æ¯”åˆ†æèšç„¦åº¦
    compare_analysis_focus()
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print("=" * 70)
    
    if focused_ok:
        print("ğŸ‰ èšç„¦HTTPåˆ†æåŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
        print("\nâœ… æ ¸å¿ƒç‰¹ç‚¹:")
        print("   - åŸŸå-IP-æ—¶å»¶ä¸‰å…ƒå…³è”åˆ†æ")
        print("   - ç›´æ¥å®šä½æ€§èƒ½é—®é¢˜åˆ°å…·ä½“ç½‘ç«™")
        print("   - å»é™¤æ— å…³ä¿¡æ¯ï¼Œèšç„¦æ ¸å¿ƒæŒ‡æ ‡")
        print("   - æä¾›å¯æ“ä½œçš„è¯Šæ–­çº¿ç´¢")
        
        print("\nğŸ¯ åˆ†æèšç„¦åº¦:")
        print("   - æ¯ä¸ªç½‘ç«™çš„IPåœ°å€åˆ—è¡¨")
        print("   - æ¯ä¸ªç½‘ç«™çš„HTTPå“åº”æ—¶é—´ç»Ÿè®¡")
        print("   - æ¯ä¸ªç½‘ç«™çš„TCP RTTç»Ÿè®¡")
        print("   - æ¯ä¸ªç½‘ç«™çš„é”™è¯¯ç‡å’Œé”™è¯¯ç±»å‹")
        print("   - æ€§èƒ½é—®é¢˜ç›´æ¥å…³è”åˆ°å…·ä½“åŸŸå")
        
        print("\nğŸ’¡ AIåˆ†æä»·å€¼:")
        print("   - å¯ä»¥ç²¾ç¡®å›ç­”ç½‘ç«™æ€§èƒ½é—®é¢˜")
        print("   - æä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®")
        print("   - æ”¯æŒé—®é¢˜æ ¹å› åˆ†æ")
        
    else:
        print("âŒ èšç„¦HTTPåˆ†æåŠŸèƒ½å¼‚å¸¸")
        print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
        print("   - æµ‹è¯•æµé‡ç”Ÿæˆå¤±è´¥")
        print("   - tshark HTTPè§£æé—®é¢˜")
        print("   - ä»£ç ä¿®æ”¹æœªç”Ÿæ•ˆ")
    
    return focused_ok

if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)
