#!/usr/bin/env python3
"""
æµ‹è¯•æ¸…ç†åçš„æ•°æ®ç»“æ„
éªŒè¯æ˜¯å¦ç§»é™¤äº†æ— å…³å­—æ®µ
"""

import requests
import time
import threading
import json

def generate_website_traffic():
    """ç”Ÿæˆç½‘ç«™è®¿é—®æµé‡"""
    print("ğŸŒ ç”Ÿæˆç½‘ç«™è®¿é—®æµé‡...")
    
    def make_requests():
        urls = [
            'https://httpbin.org/get',
            'https://example.com',
            'https://www.google.com',
        ]
        for url in urls:
            try:
                print(f"   è®¿é—®: {url}")
                requests.get(url, timeout=8)
                time.sleep(1)
            except:
                pass
    
    thread = threading.Thread(target=make_requests)
    thread.daemon = True
    thread.start()
    return thread

def test_clean_data_structure():
    """æµ‹è¯•æ¸…ç†åçš„æ•°æ®ç»“æ„"""
    print("ğŸ§¹ æµ‹è¯•æ¸…ç†åçš„æ•°æ®ç»“æ„")
    print("=" * 60)
    
    # ç”Ÿæˆæµé‡
    traffic_thread = generate_website_traffic()
    
    # åˆ›å»ºè¯·æ±‚
    test_request = {
        "issue_type": "http",
        "duration": 8,
        "user_description": "æµ‹è¯•æ¸…ç†åçš„æ•°æ®ç»“æ„",
        "enable_ai_analysis": False
    }
    
    try:
        response = requests.post('http://localhost:8000/api/capture', json=test_request)
        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return False
        
        task_id = response.json().get('task_id')
        print(f"âœ… ä»»åŠ¡: {task_id}")
        
        # ç­‰å¾…æµé‡
        traffic_thread.join(timeout=10)
        
        # ç­‰å¾…å®Œæˆ
        for i in range(25):
            time.sleep(1)
            status_response = requests.get(f'http://localhost:8000/api/capture/status?task_id={task_id}')
            if status_response.status_code == 200:
                status = status_response.json().get('status')
                if status == 'done':
                    break
                elif status == 'error':
                    print(f"âŒ å¤±è´¥: {status_response.json().get('error')}")
                    return False
        
        # è·å–ç»“æœ
        result_response = requests.get(f'http://localhost:8000/api/capture/result?task_id={task_id}')
        if result_response.status_code != 200:
            print(f"âŒ è·å–ç»“æœå¤±è´¥")
            return False
        
        result = result_response.json().get('result', {})
        enhanced_analysis = result.get('capture_summary', {}).get('enhanced_analysis', {})
        
        print("\nğŸ“Š æ•°æ®ç»“æ„åˆ†æ:")
        
        # æ£€æŸ¥HTTPåˆ†ææ•°æ®
        http_analysis = enhanced_analysis.get('http_analysis', {})
        if http_analysis:
            print("âœ… HTTPåˆ†ææ•°æ®:")
            print(json.dumps(http_analysis, indent=2, ensure_ascii=False))
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ— å…³å­—æ®µ
            unwanted_fields = [
                'tcp_flags_distribution',
                'tcp_flags',
                'ports_used',
                'tls_handshakes',
                'connection_patterns'
            ]
            
            found_unwanted = []
            def check_unwanted(data, path=""):
                if isinstance(data, dict):
                    for key, value in data.items():
                        current_path = f"{path}.{key}" if path else key
                        if key in unwanted_fields:
                            found_unwanted.append(current_path)
                        check_unwanted(value, current_path)
                elif isinstance(data, list):
                    for i, item in enumerate(data):
                        check_unwanted(item, f"{path}[{i}]")
            
            check_unwanted(http_analysis)
            
            if found_unwanted:
                print(f"âŒ ä»åŒ…å«æ— å…³å­—æ®µ: {found_unwanted}")
            else:
                print("âœ… å·²ç§»é™¤æ‰€æœ‰æ— å…³å­—æ®µ")
            
            # æ£€æŸ¥æ–°çš„ç®€åŒ–ç»“æ„
            websites_accessed = http_analysis.get('websites_accessed', {})
            if websites_accessed:
                print(f"âœ… ç½‘ç«™è®¿é—®æ•°æ®: {len(websites_accessed)} ä¸ªç½‘ç«™")
                for site, count in list(websites_accessed.items())[:3]:
                    print(f"  ğŸ“Š {site}: {count} æ¬¡")
            else:
                print("âŒ æ²¡æœ‰ç½‘ç«™è®¿é—®æ•°æ®")
        
        # æ£€æŸ¥ç½‘ç»œè¡Œä¸ºæ•°æ®
        network_behavior = enhanced_analysis.get('network_behavior', {})
        if network_behavior:
            print(f"\nâœ… ç½‘ç»œè¡Œä¸ºæ•°æ®:")
            print(json.dumps(network_behavior, indent=2, ensure_ascii=False))
        
        # æ£€æŸ¥é—®é¢˜ç‰¹å®šæ´å¯Ÿ
        issue_insights = enhanced_analysis.get('issue_specific_insights', {})
        website_performance = issue_insights.get('website_performance', {})
        
        if website_performance:
            print(f"\nâœ… ç½‘ç«™æ€§èƒ½æ•°æ®: {len(website_performance)} ä¸ªç½‘ç«™")
            for host, perf_data in list(website_performance.items())[:2]:
                print(f"  ğŸ“Š {host}:")
                print(f"    IP: {perf_data.get('ips', [])}")
                tcp_rtt = perf_data.get('tcp_rtt', {})
                if tcp_rtt.get('avg_ms'):
                    print(f"    å»¶è¿Ÿ: {tcp_rtt['avg_ms']}ms")
                else:
                    print(f"    å»¶è¿Ÿ: æœªæµ‹é‡")
        
        # æ£€æŸ¥è¯Šæ–­çº¿ç´¢
        diagnostic_clues = enhanced_analysis.get('diagnostic_clues', [])
        if diagnostic_clues:
            print(f"\nğŸ’¡ è¯Šæ–­çº¿ç´¢ ({len(diagnostic_clues)} æ¡):")
            for clue in diagnostic_clues:
                print(f"  {clue}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {str(e)}")
        return False

def show_ideal_data_structure():
    """æ˜¾ç¤ºç†æƒ³çš„æ•°æ®ç»“æ„"""
    print("\nğŸ¯ ç†æƒ³çš„ç®€åŒ–æ•°æ®ç»“æ„:")
    print("=" * 60)
    
    ideal_structure = {
        "http_analysis": {
            "websites_accessed": {
                "httpbin.org": 3,
                "example.com": 2,
                "www.google.com": 1
            },
            "connection_summary": {
                "total_websites": 3,
                "has_https_traffic": True
            }
        },
        "issue_specific_insights": {
            "website_performance": {
                "httpbin.org": {
                    "ips": ["54.243.106.191"],
                    "tcp_rtt": {"avg_ms": 45.2, "samples": 5},
                    "requests": {"total": 3, "errors": 0, "error_rate_percent": 0},
                    "protocol": "HTTPS"
                }
            },
            "performance_issues": [
                "ğŸ“¡ slow-site.com: ç½‘ç»œå»¶è¿Ÿé«˜ (å¹³å‡150ms)"
            ]
        },
        "diagnostic_clues": [
            "ğŸŒ è®¿é—®äº† 3 ä¸ªHTTPSç½‘ç«™",
            "ğŸ“Š httpbin.org: IP: 54.243.106.191, å»¶è¿Ÿ: 45ms (æ­£å¸¸), æ— é”™è¯¯",
            "ğŸ“Š example.com: IP: 93.184.216.34, å»¶è¿Ÿ: 32ms (æ­£å¸¸), æ— é”™è¯¯"
        ]
    }
    
    print("ğŸ“‹ æ ¸å¿ƒæ•°æ®ç»“æ„:")
    print(json.dumps(ideal_structure, indent=2, ensure_ascii=False))
    
    print("\nâœ… ä¿ç•™çš„æœ‰ä»·å€¼å­—æ®µ:")
    print("  - websites_accessed: è®¿é—®çš„ç½‘ç«™åˆ—è¡¨")
    print("  - website_performance: æ¯ä¸ªç½‘ç«™çš„æ€§èƒ½æ•°æ®")
    print("  - tcp_rtt: ç½‘ç»œå»¶è¿Ÿä¿¡æ¯")
    print("  - ips: IPåœ°å€æ˜ å°„")
    print("  - diagnostic_clues: æ™ºèƒ½è¯Šæ–­çº¿ç´¢")
    
    print("\nâŒ ç§»é™¤çš„æ— å…³å­—æ®µ:")
    print("  - tcp_flags_distribution: TCPæ ‡å¿—åˆ†å¸ƒ")
    print("  - ports_used: ç«¯å£ä½¿ç”¨ç»Ÿè®¡")
    print("  - tls_handshakes: TLSæ¡æ‰‹æ¬¡æ•°")
    print("  - connection_patterns: è¿æ¥æ¨¡å¼è¯¦æƒ…")
    print("  - å…¶ä»–æŠ€æœ¯ç»†èŠ‚")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ æ•°æ®ç»“æ„æ¸…ç†éªŒè¯")
    print("=" * 70)
    
    # æµ‹è¯•æ¸…ç†åçš„æ•°æ®
    clean_ok = test_clean_data_structure()
    
    # æ˜¾ç¤ºç†æƒ³ç»“æ„
    show_ideal_data_structure()
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ æ¸…ç†éªŒè¯æ€»ç»“:")
    print("=" * 70)
    
    if clean_ok:
        print("ğŸ‰ æ•°æ®ç»“æ„æ¸…ç†æˆåŠŸï¼")
        print("\nâœ… æ¸…ç†æ•ˆæœ:")
        print("   - ç§»é™¤äº†TCPæ ‡å¿—åˆ†å¸ƒç­‰æŠ€æœ¯ç»†èŠ‚")
        print("   - ä¿ç•™äº†æ ¸å¿ƒçš„ç½‘ç«™è®¿é—®ä¿¡æ¯")
        print("   - ç®€åŒ–äº†HTTPSè¿æ¥åˆ†æ")
        print("   - èšç„¦äºç”¨æˆ·å…³å¿ƒçš„ç½‘ç«™æ€§èƒ½æ•°æ®")
        
        print("\nğŸ¯ ç°åœ¨çš„æ•°æ®ç‰¹ç‚¹:")
        print("   - ç›´æ¥æ˜¾ç¤ºè®¿é—®çš„ç½‘ç«™åˆ—è¡¨")
        print("   - æ¯ä¸ªç½‘ç«™çš„IPåœ°å€å’Œå»¶è¿Ÿ")
        print("   - ç®€æ´çš„è¯Šæ–­çº¿ç´¢")
        print("   - æ— å†—ä½™çš„æŠ€æœ¯ä¿¡æ¯")
        
    else:
        print("âŒ æ•°æ®ç»“æ„æ¸…ç†éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        print("\nğŸ’¡ å¯èƒ½éœ€è¦:")
        print("   - æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é—æ¼çš„æ— å…³å­—æ®µ")
        print("   - éªŒè¯æ ¸å¿ƒæ•°æ®æ˜¯å¦å®Œæ•´")
        print("   - ç¡®ä¿è¯Šæ–­çº¿ç´¢çš„å‡†ç¡®æ€§")
    
    return clean_ok

if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)
